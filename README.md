# üöÄ SignSense ‚Äî Traductor de Lenguaje de Se√±as Americano (ASL)

**SignSense** es un proyecto de hackathon que implementa una soluci√≥n de Visi√≥n por Computadora de baja latencia para la traducci√≥n de las **26 letras** del alfabeto manual ASL. La arquitectura usa comunicaci√≥n **Cliente‚ÄìServidor** para simular un despliegue real.

---

## ‚öôÔ∏è Estructura del Proyecto

```
signsense/
‚îú‚îÄ‚îÄ api_server.py           # üß† Backend de Inferencia (Terminal 1)
‚îú‚îÄ‚îÄ demo_client.py          # üé• Frontend de Demo (Terminal 2: C√°mara y Control)
‚îú‚îÄ‚îÄ model.py                # Definici√≥n de la arquitectura MLP (PyTorch/CUDA)
‚îú‚îÄ‚îÄ landmark_pipeline.py    # Pipeline de preprocesamiento (CLAHE, √Ångulos)
‚îî‚îÄ‚îÄ signsense_*.pkl/.pth    # Archivos de Modelo y Componentes (pesos, escalador, encoder)
```

> Los archivos entre corchetes (`[]`) indican m√≥dulos clave y los archivos `signsense_*.pkl/.pth` corresponden a los modelos/artefactos entrenados necesarios para la inferencia.

---

## üì¶ Requisitos e Instalaci√≥n

Instala las dependencias necesarias (se asume Python 3.8+):

```bash
pip install torch torchvision torchaudio Flask requests opencv-python pillow
```

> Si usas GPU, aseg√∫rate de instalar la versi√≥n de `torch` compatible con tu CUDA. Consulta la documentaci√≥n oficial de PyTorch si necesitas una versi√≥n espec√≠fica.

---

## üöÄ Despliegue y Ejecuci√≥n (Dos Terminales)

La demo requiere que el servidor y el cliente se inicien en un orden espec√≠fico.

### 1. Iniciar el Servidor (Terminal 1 ‚Äî Backend) üß†

El servidor de inferencia cargar√° los archivos del modelo (pesos, escalador y codificador) y escuchar√° en el puerto **5000**.

Abre la **Terminal 1** y ejecuta:

```bash
python api_server.py
```

Deber√≠as ver:

```
‚úÖ Servidor listo: Componentes de ML cargados exitosamente.
```

Mant√©n esta terminal abierta mientras el servidor est√© en ejecuci√≥n.

---

### 2. Iniciar la Demo (Terminal 2 ‚Äî Frontend) üé•

El cliente iniciar√° la c√°mara web y esperar√° la se√±al de inicio (`s`) para comenzar a enviar frames al servidor.

Abre la **Terminal 2** y ejecuta:

```bash
python demo_client.py
```

---

## 3. Control y Funcionamiento (L√≥gica S√≠ncrona)

Una vez que el cliente est√© en ejecuci√≥n, se abrir√° una ventana de la c√°mara web.

| Acci√≥n          | Tecla / Instrucci√≥n | Resultado / Comportamiento                                                                                                         |
| --------------- | ------------------: | ---------------------------------------------------------------------------------------------------------------------------------- |
| Iniciar Captura |        Presiona `s` | Comienza la captura: se env√≠a un frame cada **3 segundos**.                                                                        |
| L√≥gica S√≠ncrona |                   ‚Äî | No se enviar√° un nuevo frame hasta que el servidor haya respondido al frame anterior.                                              |
| Visualizaci√≥n   |                   ‚Äî | La ventana de la c√°mara mostrar√° la √∫ltima letra v√°lida reconocida. El historial de estado y conexi√≥n se imprime en la Terminal 2. |
| Finalizar       |        Presiona `q` | Detiene la c√°mara y cierra el script cliente.                                                                                      |

---

## Notas T√©cnicas

* **Preprocesamiento**: `landmark_pipeline.py` aplica mejoras de contraste (CLAHE), normalizaci√≥n de puntos clave y c√°lculo de √°ngulos relevantes para la MLP.
* **Modelo**: `model.py` contiene la definici√≥n del modelo MLP implementado en PyTorch; los pesos se cargan desde los archivos `signsense_*.pth` o `*.pkl`.
* **Comunicaci√≥n**: El cliente captura frames, extrae landmarks (si aplica) y los env√≠a al servidor v√≠a HTTP (o el m√©todo especificado en `api_server.py` / `demo_client.py`) para inferencia s√≠ncrona.
* **Latencia**: La l√≥gica est√° dise√±ada para baja latencia y evita el env√≠o concurrente de m√∫ltiples frames sin respuesta del servidor.

---

## Sugerencias / Mejoras Futuras

* Soporte para palabras completas (secuencias de letras) y detecci√≥n de palabras comunes.
* Pipeline de landmarks optimizado con modelos de detecci√≥n de manos m√°s robustos.
* Interfaz web para despliegue m√°s amigable y visualizaci√≥n del historial.
* Optimizaci√≥n y quantizaci√≥n del modelo para despliegue en dispositivos edge.

---

## Licencia

Incluye aqu√≠ la licencia que prefieras (por ejemplo, MIT).
Ejemplo:

```
MIT License
```

---

## Contacto

Si quieres colaborar, reportar issues o mejorar el proyecto: abre un *issue* en el repositorio o env√≠a un PR con tus cambios.